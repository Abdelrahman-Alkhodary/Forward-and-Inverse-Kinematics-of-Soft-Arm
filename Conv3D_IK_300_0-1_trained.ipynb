{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "seeing-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "intensive-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_matrix = pd.read_csv('./data/min_matrix.csv', names=['x', 'y', 'z'])\n",
    "max_matrix = pd.read_csv('./data/max_matrix.csv', names=['x', 'y', 'z'])\n",
    "cable_matrix = pd.read_csv('./data/cable_matrix.csv', names=['t1', 't2', 't3', 't4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "israeli-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeToTension(Dataset):\n",
    "    def __init__(self, shape_files, root_dir, min_matrix, max_matrix, cable_matrix):\n",
    "        super(ShapeToTension, self).__init__()\n",
    "        self.shape_files = shape_files\n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "        self.min_matrix = min_matrix\n",
    "        self.x_min = self.min_matrix['x'].min()\n",
    "        self.y_min = self.min_matrix['y'].min()\n",
    "        self.z_min = self.min_matrix['z'].min()\n",
    "        \n",
    "        self.max_matrix = max_matrix\n",
    "        self.x_max = self.max_matrix['x'].max()\n",
    "        self.y_max = self.max_matrix['y'].max()\n",
    "        self.z_max = self.max_matrix['z'].max()\n",
    "        \n",
    "        self.cable_matrix = cable_matrix\n",
    "        # device to put the tensors on to speed up \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.cable_matrix)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        shape_file = self.shape_files[idx]\n",
    "        shape_tensor = self.shape_matrix_to_tensor(shape_file)\n",
    "        \n",
    "        t1, t2, t3, t4 = self.cable_matrix.iloc[idx, :]\n",
    "        tensions = torch.tensor([t1, t2, t3, t4], dtype=torch.float32)\n",
    "        sample = {'shape_tensor': shape_tensor, 'tensions': tensions}\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    \n",
    "    def shape_matrix_to_tensor(self, shape_file):\n",
    "        # read shape matrix and shift the center by subtracting the minimum of each coordinate\n",
    "        matrix_dir = os.path.join(self.root_dir, shape_file)\n",
    "        shape_matrix = pd.read_csv(matrix_dir, header=None).T\n",
    "        shape_matrix.columns = ['x', 'y', 'z']\n",
    "        shape_matrix['x'] = (shape_matrix['x'] - self.x_min) / (self.x_max - self.x_min)\n",
    "        shape_matrix['y'] = (shape_matrix['y'] - self.y_min) / (self.y_max - self.y_min)\n",
    "        shape_matrix['z'] = (shape_matrix['z'] - self.z_min) / (self.z_max - self.z_min)\n",
    "        shape_matrix = round(shape_matrix * 300 * 0.99)\n",
    "\n",
    "        # tensor of the shape \n",
    "        shape_tensor = torch.zeros((1, 300,300,300), dtype=torch.float32)\n",
    "\n",
    "        # loop of the coordinates of the points of the spline shape and convert them to one\n",
    "        for index, row in shape_matrix.iterrows():\n",
    "            width, depth, height = int(row['x']), int(row['y']), int(row['z'])\n",
    "            shape_tensor[:, depth, height, width] = 1\n",
    "            \n",
    "        return shape_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lesbian-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_files_dir = './data/shape/'\n",
    "shape_files = os.listdir(shape_files_dir)\n",
    "shape_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "coupled-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "ShapeToTension_ds = ShapeToTension(shape_files=shape_files, \n",
    "                                   root_dir=shape_files_dir, \n",
    "                                   min_matrix=min_matrix,\n",
    "                                   max_matrix=max_matrix,\n",
    "                                   cable_matrix=cable_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fantastic-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "ShapeToTension_dl = DataLoader(ShapeToTension_ds, batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "vocational-occurrence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 300, 300, 300])\n"
     ]
    }
   ],
   "source": [
    "data_itr = iter(ShapeToTension_dl)\n",
    "sample = next(data_itr)\n",
    "print(sample['shape_tensor'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "together-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv3D, self).__init__()\n",
    "        self.conv1_set = nn.Sequential(nn.Conv3d(1, 4, kernel_size=4, stride=2),\n",
    "                                       nn.BatchNorm3d(4),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.MaxPool3d(2))\n",
    "        self.conv2_set = nn.Sequential(nn.Conv3d(4, 8, kernel_size=4, stride=2),\n",
    "                                       nn.BatchNorm3d(8),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.MaxPool3d(2))\n",
    "        self.conv3_set = nn.Sequential(nn.Conv3d(8, 16, kernel_size=4, stride=2),\n",
    "                                       nn.BatchNorm3d(16),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.MaxPool3d(2))\n",
    "        self.fc1 = nn.Sequential(nn.Linear(1024, 512),\n",
    "                                 nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(nn.Linear(512, 128),\n",
    "                                 nn.ReLU())\n",
    "        self.fc3 = nn.Linear(128, 4)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1_set(x)\n",
    "        x = self.conv2_set(x)\n",
    "        x = self.conv3_set(x)\n",
    "        x = torch.flatten(x,start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "liable-portfolio",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_itr = iter(ShapeToTension_dl)\n",
    "sample = data_itr.next()\n",
    "model = Conv3D()\n",
    "out = model(sample['shape_tensor'])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "amber-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "def train_model(train_dl, model):\n",
    "    model.train()\n",
    "    # define the optimization\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    # enumerate epochs\n",
    "    for epoch in range(20):\n",
    "        loss_arr = []\n",
    "        # enumerate mini batches\n",
    "        for i, sample_batch in tqdm(enumerate(train_dl)):\n",
    "            # clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # compute the model output\n",
    "            yhat = model(sample_batch['shape_tensor'].to(device))\n",
    "            # calculate loss\n",
    "            loss = criterion(yhat, sample_batch['tensions'].to(device))\n",
    "            loss_arr.append(loss.item())\n",
    "            # credit assignment\n",
    "            loss.backward()\n",
    "            # update model weights\n",
    "            optimizer.step()\n",
    "        if epoch % 10 == 0 or epoch == 0:\n",
    "            print('Epoch: {}, mean loss: {}'.format(epoch, np.mean(loss_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "proud-finance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ShapeToTension_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "light-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lengths = [int(len(ShapeToTension_ds)*0.8)]\n",
    "ShapeToTension_ds_sub_A, ShapeToTension_ds_sub_B = random_split(ShapeToTension_ds, lengths=[100000, 150000])\n",
    "ShapeToTension_ds_train, ShapeToTension_ds_test = random_split(ShapeToTension_ds_sub_A, lengths=[80000, 20000])\n",
    "\n",
    "ShapeToTension_dl_train = DataLoader(ShapeToTension_ds_train, batch_size=16,shuffle=True)\n",
    "ShapeToTension_dl_test = DataLoader(ShapeToTension_ds_test, batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "illegal-cabinet",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [2:04:14,  1.49s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, mean loss: 3.8326760459303855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [2:00:55,  1.45s/it]\n",
      "5000it [2:01:12,  1.45s/it]\n",
      "5000it [2:00:20,  1.44s/it]\n",
      "5000it [2:00:15,  1.44s/it]\n",
      "5000it [2:00:23,  1.44s/it]\n",
      "5000it [2:00:32,  1.45s/it]\n",
      "5000it [2:01:02,  1.45s/it]\n",
      "5000it [2:00:58,  1.45s/it]\n",
      "5000it [1:59:30,  1.43s/it]\n",
      "5000it [2:00:19,  1.44s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, mean loss: 1.819358343565464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [2:02:48,  1.47s/it]\n",
      "5000it [2:03:45,  1.49s/it]\n",
      "5000it [1:56:55,  1.40s/it]\n",
      "5000it [1:56:11,  1.39s/it]\n",
      "5000it [1:56:19,  1.40s/it]\n",
      "5000it [1:56:27,  1.40s/it]\n",
      "5000it [1:56:04,  1.39s/it]\n",
      "5000it [1:56:30,  1.40s/it]\n",
      "5000it [1:56:26,  1.40s/it]\n"
     ]
    }
   ],
   "source": [
    "model = Conv3D().cuda()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "# train the model\n",
    "train_model(ShapeToTension_dl_train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "typical-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a path\n",
    "PATH = \"model300_wBN_DrBerkeCode_80KS_0-1.pt\"\n",
    "\n",
    "# Save\n",
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-society",
   "metadata": {},
   "source": [
    "# Testing #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "extreme-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "def test_model(test_dl, model):\n",
    "    model.eval()\n",
    "    abs_error = torch.zeros([len(test_dl),4]).to('cuda')\n",
    "    for i, sample_batch in tqdm(enumerate(test_dl)):\n",
    "        # compute the model output\n",
    "        yhat = model(sample_batch['shape_tensor'].to('cuda'))\n",
    "        # retrieve numpy array\n",
    "        yhat = yhat.detach()\n",
    "        targets = sample_batch['tensions'].to('cuda')\n",
    "        abs_error[i,:] = torch.absolute(targets - yhat)\n",
    "    return abs_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65b4f719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [32:26, 10.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# test the model 0-1\n",
    "# test the model IK\n",
    "abs_error_accumulated = test_model(ShapeToTension_dl_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4aeb818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0254, 1.0657, 1.0362, 1.0562], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_error_accumulated.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd9bb7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7901, 0.8275, 0.7977, 0.8048], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_error_accumulated.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e679a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
